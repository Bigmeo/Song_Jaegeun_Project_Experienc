{"cells":[{"cell_type":"markdown","id":"87aed3d6","metadata":{"id":"87aed3d6"},"source":["# 1. 라이브러리 및 데이터 불러오기"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Tav7RqlwIHYj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ae85f5d-d430-4b76-faa5-b7a9124dc10c"},"id":"Tav7RqlwIHYj","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#### tensorflow_addons : f1_score을 쓰기 위해 설치"],"metadata":{"id":"hPbLpthAf58F"},"id":"hPbLpthAf58F"},{"cell_type":"code","source":["!pip install tensorflow_addons"],"metadata":{"id":"VVGmX6DnIJ7C"},"id":"VVGmX6DnIJ7C","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 기본\n","import numpy as np\n","import pandas as pd\n","\n","import os\n","import glob\n","import shutil\n","\n","import math\n","import random\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import cv2\n","\n","# 이미지 수정\n","import albumentations as A\n","\n","# sklearn\n","from sklearn import preprocessing\n","from sklearn.model_selection import StratifiedKFold\n","\n","# tensorflow\n","import tensorflow as tf\n","from tensorflow.keras import applications, callbacks\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.utils import Sequence, to_categorical\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import tensorflow_addons as tfa\n","\n","# warning 알림 끄기\n","import warnings\n","warnings.filterwarnings(action='ignore')"],"metadata":{"id":"50KtqEmDHrIP"},"id":"50KtqEmDHrIP","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. 모델 생성"],"metadata":{"id":"4xMoVUNbIMSx"},"id":"4xMoVUNbIMSx"},{"cell_type":"markdown","source":["## 1) 클래스 및 함수 선언\n"],"metadata":{"id":"r8jNnfxoi7IS"},"id":"r8jNnfxoi7IS"},{"cell_type":"markdown","source":["#### 결과를 재현하기 위한 seed 고정"],"metadata":{"id":"Y3wu5j_LM4mi"},"id":"Y3wu5j_LM4mi"},{"cell_type":"code","source":["# seed 고정(random_state=42)\n","def seed_everything(seed : int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    tf.random.set_seed(seed)\n","\n","seed_everything(42)"],"metadata":{"id":"7QEOGl_cVL4S"},"id":"7QEOGl_cVL4S","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각종 파라미터의 디폴트값\n","Default_param = {\n","    'IMG_SIZE' : 224,\n","    'EPOCHS' : 50,\n","    'LEARNING_RATE' : 1e-3,\n","    'BATCH_SIZE' : 16,\n","    'SEED' : 42\n","}"],"metadata":{"id":"IIrIcZH2IRRb"},"id":"IIrIcZH2IRRb","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# csv 파일에서 이미지 파일의 주소를 가져오는 함수\n","def get_data(df, infer=False):\n","\n","    # 라벨 데이터(화가 이름)가 없는 경우 이미지 파일의 주소만 가져옴 → test.csv\n","    if infer:\n","        return df['img_path'].values\n","\n","    # 라벨 데이터(화가 이름)가 있는 경우 이미지 파일의 주소와 라벨을 모두 가져옴 → train.csv\n","    return df['img_path'].values, df['artist'].values "],"metadata":{"id":"pybwyKFDIRTZ"},"id":"pybwyKFDIRTZ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 라벨 인코딩 및 이미지 파일 경로 조정"],"metadata":{"id":"sHrp9iY3NnRR"},"id":"sHrp9iY3NnRR"},{"cell_type":"code","source":["# train 불러오기\n","df = pd.read_csv('/content/drive/MyDrive/2nd_project/data/train.csv')\n","\n","# 라벨 데이터 One-Hot Encoding\n","le = preprocessing.LabelEncoder()\n","df['artist'] = le.fit_transform(df['artist'].values)\n","\n","# test 불러오기\n","test_df = pd.read_csv('/content/drive/MyDrive/2nd_project/data/test.csv')\n","test_df['img_path'] = test_df['img_path'].apply(lambda x:'/content/drive/MyDrive/2nd_project' + x[1:])\n","test_img_paths = get_data(test_df, infer=True)"],"metadata":{"id":"qEINyjrHIRVR"},"id":"qEINyjrHIRVR","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 학습의 속도를 높여주는 scheduler\n","#### tensorflow에서는 torch와 다르게 scheduler를 제공하지 않으므로 직접 만들어야 함\n","#### 밑에서는 stepLR을 직접 구현"],"metadata":{"id":"FOZML4alrDhn"},"id":"FOZML4alrDhn"},{"cell_type":"code","source":["# scheduler\n","def lr_step_decay(epoch, lr):\n","    drop_rate = 0.5\n","    epochs_drop = 5.0\n","    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))"],"metadata":{"id":"5IcnYB_MmjOI"},"id":"5IcnYB_MmjOI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def step_decay(epoch):\n","    start = 1e-3\n","    drop = 0.5\n","    epochs_drop = 5.0\n","    lr = start * (drop ** np.floor((epoch)/epochs_drop))\n","    return lr\n","\n","lr_scheduler = callbacks.LearningRateScheduler(step_decay, verbose=1)"],"metadata":{"id":"BNKKZsXgntLj"},"id":"BNKKZsXgntLj","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 이미지 데이터가 용량이 커서 한번에 다 불러올 수 없는 문제가 발생\n","#### → img_path만을 가지고 있다가 필요할 때만 이 클래스를 통해 미니배치마다 이미지를 cv2로 읽어서 가져옴"],"metadata":{"id":"Ahq8PCzAONfJ"},"id":"Ahq8PCzAONfJ"},{"cell_type":"markdown","source":["#### torch와 다르게 tensorflow는 dataloader가 없음\n","#### 따라서 dataset에서 '__len__'과 '__getitem__'에서 batch size만큼의 데이터를 가져올 수 있게 클래스를 수정"],"metadata":{"id":"ooZaQ2vngQzV"},"id":"ooZaQ2vngQzV"},{"cell_type":"code","source":["# 데이터를 불러오는 클래스\n","class CustomDataset(Sequence):\n","    def __init__(self, img_paths, augmentations, batch_size ,labels=None):\n","        self.labels = labels\n","        self.img_paths = img_paths\n","        self.batch_size = batch_size\n","        self.augment = augmentations\n","        self.length = len(img_paths)\n","        \n","    def __len__(self):\n","        return int(np.ceil(len(self.img_paths) / float(self.batch_size)))\n","\n","    # 지정 배치 크기만큼 데이터를 로드\n","    def __getitem__(self, idx):\n","        if self.length >= (idx + 1) * self.batch_size:\n","            inds = np.arange(idx * self.batch_size,(idx + 1) * self.batch_size)\n","        else:\n","            inds = np.arange(idx * self.batch_size,self.length)\n","\n","        img_path = self.img_paths[inds]\n","        batch_x = [cv2.cvtColor(cv2.imread(x), cv2.COLOR_BGR2RGB) for x in img_path]\n","\n","        if self.labels is not None:\n","            batch_label = self.labels[inds]\n","      \n","            # augmentation을 적용해서 numpy array에 stack\n","            return np.stack([self.augment(image=x)[\"image\"] for x in batch_x], axis=0), np.array(batch_label)\n","        else:\n","            return np.array([self.augment(image=x)[\"image\"] for x in batch_x])"],"metadata":{"id":"x5Z9so_Ymwny"},"id":"x5Z9so_Ymwny","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 이미지 사이즈 조정 및 이미지 데이터 증폭"],"metadata":{"id":"ZVYbBhejrMa_"},"id":"ZVYbBhejrMa_"},{"cell_type":"code","source":["train_transform = A.Compose(\n","    [\n","        A.Resize(p=1, height=224*2, width=224*2),\n","        A.RandomCrop(p=1,height=224,width=224),\n","        A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p = 0.5),\n","        A.OneOf([\n","                                            A.MotionBlur(p=1),\n","                                            A.OpticalDistortion(p=1),\n","                                            A.GaussNoise(p=1)\n","                ], p= 0.3),\n","        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.3),\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n","        ])\n","\n","test_transform = A.Compose(\n","    [\n","        A.Resize(height=224, width=224),\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n","        ])"],"metadata":{"id":"3-klXwKJnnNR"},"id":"3-klXwKJnnNR","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2) 학습 진행"],"metadata":{"id":"WdKJ4YM7oMB4"},"id":"WdKJ4YM7oMB4"},{"cell_type":"markdown","source":["### EfficientNet_B4 베이스 모델 + StratifiedKFold\n","#### 전이학습에 EfficientNet_B4 모델을 사용한 이유 : ResNet 등 다른 모델에 비해 10배 가량 가벼우면서 훨씬 좋은 성능을 보여줌\n","#### StratifiedKFold : kfold에 라벨의 비율을 적용해서 데이터가 일정한 라벨 비율을 갖도록 하는 방법"],"metadata":{"id":"JPMP-5iloNXQ"},"id":"JPMP-5iloNXQ"},{"cell_type":"markdown","source":["#### fold 하나당 소요되는 시간이 매우 길기 때문에 fold 1개를 수행할 때마다 torch 파일로 저장\n","#### → 학습 모델을 통해 test 데이터를 예측한 결과도 npy 파일로 저장\n","#### → kfold에서 지정한 split 횟수만큼 반복한 후, 그 결과들을 활용하여 voting 진행\n","#### → 단순히 예측 결과를 더한 뒤 argmax함수를 적용하는 soft voting(probability voting이라고도 함)"],"metadata":{"id":"scSejv5ooNZI"},"id":"scSejv5ooNZI"},{"cell_type":"markdown","source":["#### torch와 유사한 형태로 구성\n","#### 여기서는 flatten과 batchnormalization을 주었지만 없어도 무방할 것으로 생각됨\n","#### torch에 비해 학습이 불안정하며 scheduler나 fold에 따라 그 불안정성이 더 심해지는 경우가 많음\n","#### scheduler의 파라메터 조정을 잘 해주지 않으면 제대로 된 학습을 하지 못하는 경우가 많음\n","#### f1_score는 최대 67% ~ 68% 정도 나오지만 중간에 학습이 끊기거나 일부 fold는 수렴이 느려 f1_score가 50% 대에 머물기도 함\n","#### 또한 torch에 비해 과적합이 심하고 val_loss와 val_f1_score의 차가 극단적으로 큰 경우가 생기며 epoch마다 값의 편차가 무척 큼"],"metadata":{"id":"kCZt0g-FgtD8"},"id":"kCZt0g-FgtD8"},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=5, shuffle=False) # 구현, 5 fold, shuffle 안함\n","t = df.artist # 라벨\n","\n","# model 폴더 만드는 함수\n","os.mkdir('drive/MyDrive/2nd_project/model')\n","\n","# StratifiedKFold 객체는 split에 라벨도 함께 적용하는 것으로, 라벨이 같은 비율을 갖도록 index를 반환해줌\n","for fold, (train_index, test_index) in enumerate(skf.split(np.zeros(len(t)), t)):\n","\n","    # 하나의 fold를 실행하는 데 많은 시간이 걸리므로 fold 한 개마다 저장하는 식으로 했음\n","    if fold!=0:\n","        print(f'skip {fold}')\n","        continue\n","\n","    # train split\n","    train_df = df.loc[train_index]\n","\n","    # validation split\n","    val_df = df.loc[test_index]\n","\n","    # train 이미지 주소 가져오기\n","    train_img_paths, train_labels = get_data(train_df)\n","\n","    # val 이미지 주소 가져오기\n","    val_img_paths, val_labels = get_data(val_df)\n","\n","    # One-Hot Encoding\n","    one_train_labels = tf.keras.utils.to_categorical(train_labels)\n","    one_val_labels = tf.keras.utils.to_categorical(val_labels)\n","\n","    train_gen = CustomDataset(train_img_paths, train_transform ,Default_param['BATCH_SIZE'], one_train_labels)\n","    val_gen = CustomDataset(val_img_paths, train_transform, Default_param['BATCH_SIZE'], one_val_labels)\n","    test_gen = CustomDataset(test_img_paths, test_transform, Default_param['BATCH_SIZE'])\n","\n","    # 모델 구성\n","    model = Sequential([applications.efficientnet.EfficientNetB4(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='avg', classes=1000),\n","                        Flatten(), BatchNormalization(), Dense(50, activation='softmax')])\n","    # cos_decay_ann = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=Default_param['LEARNING_RATE'], first_decay_steps=2, t_mul=1, m_mul=0.99, alpha=1e-5)\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=Default_param['LEARNING_RATE'])\n","\n","    # compile\n","    model.compile(optimizer=optimizer, loss=tf.keras.losses.categorical_crossentropy, metrics=[tfa.metrics.F1Score(num_classes=50, average='macro')])\n","\n","    # 조기종료\n","    earlystop = callbacks.EarlyStopping(monitor='val_f1_score', mode='max', patience=10, restore_best_weights=True)\n","\n","    # train 학습\n","    model.fit(train_gen,epochs=100, validation_data=val_gen, callbacks=[earlystop, lr_scheduler])\n","    model.save('/content/drive/MyDrive/2nd_project/kfold/' + str(fold) + '.keras')\n","\n","    # test 예측\n","    predict = model.predict(test_gen)\n","    predict = np.array(predict)\n","    np.save('/content/drive/MyDrive/2nd_project/kfold/' + str(fold) + 'keras.npy', predict)"],"metadata":{"id":"rMgc3L8kn48W"},"id":"rMgc3L8kn48W","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. 결과"],"metadata":{"id":"A-FPhRAGpmI8"},"id":"A-FPhRAGpmI8"},{"cell_type":"code","source":["files = glob.glob('/content/drive/MyDrive/2nd_project/kfold/*keras.npy')\n","files"],"metadata":{"id":"5OWX6pCLhspb"},"id":"5OWX6pCLhspb","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict = np.load(files[0]) + np.load(files[1])\n","predict.shape"],"metadata":{"id":"GH2mpgHBhsue"},"id":"GH2mpgHBhsue","execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = le.inverse_transform(predict.argmax(1))\n","submit = pd.read_csv('/content/drive/MyDrive/2nd_project/data/sample_submission.csv')\n","submit['artist'] = preds\n","submit.to_csv('/content/drive/MyDrive/2nd_project/submit_keras0.csv', index=False)"],"metadata":{"id":"jXx-Q0HMIR0v"},"id":"jXx-Q0HMIR0v","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6bVYwim6n9SG"},"id":"6bVYwim6n9SG","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[],"collapsed_sections":["Ahq8PCzAONfJ","scSejv5ooNZI"]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}